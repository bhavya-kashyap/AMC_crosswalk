{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!apt update\n",
        "!apt install chromium-chromedriver\n",
        "!pip install selenium\n",
        "!pip install bs4"
      ],
      "metadata": {
        "id": "Cgh84PJPKAeP",
        "outputId": "722b5828-83f5-4a3d-8c11-9e5bd4c7aaac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Cgh84PJPKAeP",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Get:2 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Ign:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:8 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [83.3 kB]\n",
            "Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:12 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [3,020 kB]\n",
            "Get:13 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [1,230 kB]\n",
            "Get:15 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,329 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,551 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [1,188 kB]\n",
            "Get:19 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [2,164 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,452 kB]\n",
            "Get:21 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [1,109 kB]\n",
            "Get:22 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [45.3 kB]\n",
            "Get:23 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [50.8 kB]\n",
            "Fetched 16.5 MB in 8s (1,976 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "40 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-codecs-ffmpeg-extra\n",
            "Suggested packages:\n",
            "  webaccounts-chromium-extension unity-chromium-extension\n",
            "The following NEW packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-chromedriver\n",
            "  chromium-codecs-ffmpeg-extra\n",
            "0 upgraded, 4 newly installed, 0 to remove and 40 not upgraded.\n",
            "Need to get 91.7 MB of archives.\n",
            "After this operation, 309 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-codecs-ffmpeg-extra amd64 105.0.5195.102-0ubuntu0.18.04.1 [1,156 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser amd64 105.0.5195.102-0ubuntu0.18.04.1 [80.1 MB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser-l10n all 105.0.5195.102-0ubuntu0.18.04.1 [5,097 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-chromedriver amd64 105.0.5195.102-0ubuntu0.18.04.1 [5,320 kB]\n",
            "Fetched 91.7 MB in 10s (9,439 kB/s)\n",
            "Selecting previously unselected package chromium-codecs-ffmpeg-extra.\n",
            "(Reading database ... 123934 files and directories currently installed.)\n",
            "Preparing to unpack .../chromium-codecs-ffmpeg-extra_105.0.5195.102-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-codecs-ffmpeg-extra (105.0.5195.102-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-browser.\n",
            "Preparing to unpack .../chromium-browser_105.0.5195.102-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-browser (105.0.5195.102-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-browser-l10n.\n",
            "Preparing to unpack .../chromium-browser-l10n_105.0.5195.102-0ubuntu0.18.04.1_all.deb ...\n",
            "Unpacking chromium-browser-l10n (105.0.5195.102-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-chromedriver.\n",
            "Preparing to unpack .../chromium-chromedriver_105.0.5195.102-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-chromedriver (105.0.5195.102-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-codecs-ffmpeg-extra (105.0.5195.102-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-browser (105.0.5195.102-0ubuntu0.18.04.1) ...\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n",
            "Setting up chromium-chromedriver (105.0.5195.102-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-browser-l10n (105.0.5195.102-0ubuntu0.18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.6) ...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting selenium\n",
            "  Downloading selenium-4.5.0-py3-none-any.whl (995 kB)\n",
            "\u001b[K     |████████████████████████████████| 995 kB 4.3 MB/s \n",
            "\u001b[?25hCollecting urllib3[socks]~=1.26\n",
            "  Downloading urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 55.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.7/dist-packages (from selenium) (2022.9.24)\n",
            "Collecting trio~=0.17\n",
            "  Downloading trio-0.22.0-py3-none-any.whl (384 kB)\n",
            "\u001b[K     |████████████████████████████████| 384 kB 55.3 MB/s \n",
            "\u001b[?25hCollecting trio-websocket~=0.9\n",
            "  Downloading trio_websocket-0.9.2-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (22.1.0)\n",
            "Collecting outcome\n",
            "  Downloading outcome-1.2.0-py2.py3-none-any.whl (9.7 kB)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Collecting exceptiongroup>=1.0.0rc9\n",
            "  Downloading exceptiongroup-1.0.0rc9-py3-none-any.whl (12 kB)\n",
            "Collecting async-generator>=1.9\n",
            "  Downloading async_generator-1.10-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (2.10)\n",
            "Collecting sniffio\n",
            "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
            "Collecting wsproto>=0.14\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
            "Collecting h11<1,>=0.9.0\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 5.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from h11<1,>=0.9.0->wsproto>=0.14->trio-websocket~=0.9->selenium) (4.1.1)\n",
            "Installing collected packages: sniffio, outcome, h11, exceptiongroup, async-generator, wsproto, urllib3, trio, trio-websocket, selenium\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "requests 2.23.0 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you have urllib3 1.26.12 which is incompatible.\u001b[0m\n",
            "Successfully installed async-generator-1.10 exceptiongroup-1.0.0rc9 h11-0.14.0 outcome-1.2.0 selenium-4.5.0 sniffio-1.3.0 trio-0.22.0 trio-websocket-0.9.2 urllib3-1.26.12 wsproto-1.2.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.7/dist-packages (0.0.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from bs4) (4.6.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "da829f11",
      "metadata": {
        "id": "da829f11"
      },
      "outputs": [],
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.common.by import By\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd         \n",
        "import ctypes"
      ],
      "metadata": {
        "id": "d4y6X6wfPXFr"
      },
      "id": "d4y6X6wfPXFr",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arizona = 'https://raw.githubusercontent.com/bhavya-kashyap/web-scrapping/main/States_raw_data/Arizona.csv'\n",
        "alabama = 'https://raw.githubusercontent.com/bhavya-kashyap/web-scrapping/main/States_raw_data/Alabama.csv'\n",
        "alaska = 'https://raw.githubusercontent.com/bhavya-kashyap/web-scrapping/main/States_raw_data/Alaska.csv'\n",
        "Arkansas = 'https://raw.githubusercontent.com/bhavya-kashyap/web-scrapping/main/States_raw_data/Arkansas.csv'\n",
        "California = 'https://raw.githubusercontent.com/bhavya-kashyap/web-scrapping/main/States_raw_data/California.csv'\n",
        "Colorado = 'https://raw.githubusercontent.com/bhavya-kashyap/web-scrapping/main/States_raw_data/Colorado.csv'\n",
        "Conneticut = 'https://raw.githubusercontent.com/bhavya-kashyap/web-scrapping/main/States_raw_data/Conneticut.csv'\n",
        "Celaware = 'https://raw.githubusercontent.com/bhavya-kashyap/web-scrapping/main/States_raw_data/Delaware.csv'\n",
        "Coc = 'https://github.com/bhavya-kashyap/AMC_crosswalk/blob/main/States_raw_data/District_of_Columbia.csv'\n",
        "Florida = 'https://raw.githubusercontent.com/bhavya-kashyap/web-scrapping/main/States_raw_data/Florida.csv'\n",
        "idaho = 'https://raw.githubusercontent.com/bhavya-kashyap/web-scrapping/main/States_raw_data/Idaho.csv'\n",
        "illinois = 'https://raw.githubusercontent.com/bhavya-kashyap/web-scrapping/main/States_raw_data/Illinois.csv'\n",
        "indiana = 'https://raw.githubusercontent.com/bhavya-kashyap/web-scrapping/main/States_raw_data/Indiana.csv'\n",
        "iowa = 'https://raw.githubusercontent.com/bhavya-kashyap/web-scrapping/main/States_raw_data/Iowa.csv'\n",
        "kansas = 'https://raw.githubusercontent.com/bhavya-kashyap/web-scrapping/main/States_raw_data/Kansas.csv'\n",
        "kentucky = 'https://raw.githubusercontent.com/bhavya-kashyap/web-scrapping/main/States_raw_data/Kentucky.csv'\n",
        "states = [Arkansas, California, Colorado, Conneticut, Delaware, Doc, Florida]\n",
        "state_name = ['Arkansas', \"California\", \"Colorado\", \"Conneticut\", \"Delaware\", \"Doc\", \"Florida\"]"
      ],
      "metadata": {
        "id": "fWXpjwr6YI6e"
      },
      "id": "fWXpjwr6YI6e",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " for i in range(len(states)):\n",
        "  hospitals = pd.read_csv(states[i])\n",
        "  hospitals = hospitals[hospitals['AMC_No'].notna()]\n",
        "  hospitals['AMC_No'] = hospitals[\"AMC_No\"].astype(int)\n",
        "\n",
        "  baseurl = 'https://freida.ama-assn.org/institution/'\n",
        "  URLS = []\n",
        "  for index, i in hospitals.iterrows():\n",
        "    URLS.append(str(baseurl + str(i['AMC_No'])))\n",
        "  hospitals['URLS'] = URLS\n",
        "  len(hospitals)\n",
        "  def driversetup():\n",
        "      options = webdriver.ChromeOptions()\n",
        "      #run Selenium in headless mode\n",
        "      options.add_argument('--headless')\n",
        "      options.add_argument('--no-sandbox')\n",
        "      options.add_argument(\"enable-automation\")\n",
        "      #overcome limited resource problems\n",
        "      options.add_argument('--disable-dev-shm-usage')\n",
        "      options.add_argument(\"lang=en\")\n",
        "      #open Browser in maximized mode\n",
        "      options.add_argument(\"start-maximized\")\n",
        "      #disable infobars\n",
        "      options.add_argument(\"disable-infobars\")\n",
        "      #disable extension\n",
        "      options.add_argument(\"--disable-browser-side-navigation\")\n",
        "      options.add_argument(\"--disable-gpu\")\n",
        "      options.add_argument(\"--disable-extensions\")\n",
        "      options.add_argument(\"--incognito\")\n",
        "      options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
        "      \n",
        "      driver = webdriver.Chrome(options=options)\n",
        "\n",
        "      driver.execute_script(\"Object.defineProperty(navigator, 'webdriver', {get: () => undefined});\")\n",
        "\n",
        "      return driver\n",
        "\n",
        "  def pagesource(url, driver):\n",
        "      driver = driver\n",
        "      driver.get(url)\n",
        "      time.sleep(12)\n",
        "      soup = BeautifulSoup(driver.page_source)\n",
        "      #driver.close()\n",
        "      return soup\n",
        "  \n",
        "  mc = []\n",
        "  grad = []\n",
        "  mcl = []\n",
        "  add = []\n",
        "  d = driversetup()\n",
        "  for index, i in hospitals.iterrows():\n",
        "    url = i['URLS']\n",
        "    s = pagesource(url, d)\n",
        "    med_school = list(s.findAll('small', class_=\"bold\"))\n",
        "    address = list(s.findAll('div', class_=\"details__address ng-star-inserted\")) \n",
        "    if len(med_school) == 0:\n",
        "      mc.append(\"\")\n",
        "      mcl.append(\"\")\n",
        "      grad.append(\"\")\n",
        "    elif len(med_school) == 1:\n",
        "      a = list(s.findAll('div', class_=\"medical-schools__school ng-star-inserted\"))\n",
        "      name = a[0].findAll('small', class_='bold')[0].text\n",
        "      relationship = a[0].findAll('div', class_='')[0].text\n",
        "      if 'Limited' in relationship:\n",
        "        mcl.append(name)\n",
        "        mc.append(\"\")\n",
        "        grad.append(\"\")\n",
        "      elif 'Major' in relationship:\n",
        "        mc.append(name)\n",
        "        mcl.append(\"\")\n",
        "        grad.append(\"\")\n",
        "      elif 'Graduate' in relationship:\n",
        "        mc.append(\"\")\n",
        "        mcl.append(\"\")\n",
        "        grad.append(name)\n",
        "      else:\n",
        "        print(\"NEW RELATIONSHIP FOUND : \", name)\n",
        "        break\n",
        "    elif len(med_school) > 1:   \n",
        "        major = []\n",
        "        limited = []\n",
        "        graduate = []\n",
        "        a = list(s.findAll('div', class_=\"medical-schools__school ng-star-inserted\"))\n",
        "        for i in range(len(a)):\n",
        "          name = a[i].findAll('small', class_='bold')[0].text\n",
        "          relationship = a[i].findAll('div', class_='')[0].text\n",
        "          if 'Limited' in relationship:\n",
        "            limited.append(name)\n",
        "          elif 'Graduate' in relationship:\n",
        "            graduate.append(name)\n",
        "          elif 'Major' in relationship:\n",
        "            major.append(name)\n",
        "          else:\n",
        "            print(\"New relationship found\")\n",
        "            break \n",
        "        if major == []:\n",
        "          major = ''\n",
        "        if limited == []:\n",
        "          limited = ''\n",
        "        if grad == []:\n",
        "          grad = ''\n",
        "        mc.append(major)\n",
        "        mcl.append(limited)\n",
        "        grad.append(graduate)\n",
        "    if len(address) != 0:\n",
        "      address[0].br.string = ', '\n",
        "      add.append(address[0].text)\n",
        "    else:\n",
        "      add.append(\"\")\n",
        "    print(index, 'mc', len(mc), mc[index], 'mcl', len(mcl), mcl[index], 'grad', len(grad), grad[index], 'add', len(add), add[index])\n",
        "    if len(mc) > (index+1):\n",
        "      break\n",
        "    \n",
        "  print(len(mc),len(mcl),len(grad),len(add))\n",
        "  hospitals['Affiliation_Major'] = mc\n",
        "  hospitals['Affiliation_Limited'] = mcl\n",
        "  hospitals['Affiliation_Graduate'] = grad\n",
        "  hospitals['Medical_Center_Address'] = add \n",
        "  hospitals.to_csv('{}_crosswalk.csv').format(state_name[i])\n",
        "\n"
      ],
      "metadata": {
        "id": "myu67DvrpDA-"
      },
      "id": "myu67DvrpDA-",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(hospitals)"
      ],
      "metadata": {
        "id": "jf3AX42Zq-4H",
        "outputId": "a8995221-72d1-4a00-a922-5494e248a1c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "jf3AX42Zq-4H",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "113"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "b2484332",
      "metadata": {
        "id": "b2484332"
      },
      "outputs": [],
      "source": [
        "# def driversetup():\n",
        "#     options = webdriver.ChromeOptions()\n",
        "#     #run Selenium in headless mode\n",
        "#     options.add_argument('--headless')\n",
        "#     options.add_argument('--no-sandbox')\n",
        "#     options.add_argument(\"enable-automation\")\n",
        "#     #overcome limited resource problems\n",
        "#     options.add_argument('--disable-dev-shm-usage')\n",
        "#     options.add_argument(\"lang=en\")\n",
        "#     #open Browser in maximized mode\n",
        "#     options.add_argument(\"start-maximized\")\n",
        "#     #disable infobars\n",
        "#     options.add_argument(\"disable-infobars\")\n",
        "#     #disable extension\n",
        "#     options.add_argument(\"--disable-browser-side-navigation\")\n",
        "#     options.add_argument(\"--disable-gpu\")\n",
        "#     options.add_argument(\"--disable-extensions\")\n",
        "#     options.add_argument(\"--incognito\")\n",
        "#     options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
        "    \n",
        "#     driver = webdriver.Chrome(options=options)\n",
        "\n",
        "#     driver.execute_script(\"Object.defineProperty(navigator, 'webdriver', {get: () => undefined});\")\n",
        "\n",
        "#     return driver\n",
        "\n",
        "# def pagesource(url, driver):\n",
        "#     driver = driver\n",
        "#     driver.get(url)\n",
        "#     time.sleep(12)\n",
        "#     soup = BeautifulSoup(driver.page_source)\n",
        "#     #driver.close()\n",
        "#     return soup\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# d = driversetup()\n",
        "# relationship = []\n",
        "# for index, i in hospitals.iterrows():\n",
        "#   url = i['URLS']\n",
        "#   s = pagesource(url, d)\n",
        "#   med_school = list(s.findAll('small', class_=\"bold\"))\n",
        "#   print(i.Med_center, index, relationship, len(med_school))\n",
        "#   for i in range(len(med_school)):\n",
        "#     a = list(s.findAll('div', class_=\"medical-schools__school ng-star-inserted\"))\n",
        "    \n",
        "#     for i in range(len(a)):\n",
        "#       rel = a[i].findAll('div', class_='')[0].text\n",
        "#       if rel not in relationship:\n",
        "#         print(med_school[i].text, rel)\n",
        "#         relationship.append(rel)\n",
        "# relationship"
      ],
      "metadata": {
        "id": "08mgmMrM6tWg"
      },
      "id": "08mgmMrM6tWg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mc = []\n",
        "# grad = []\n",
        "# mcl = []\n",
        "# add = []\n",
        "# d = driversetup()\n",
        "# for index, i in hospitals.iterrows():\n",
        "#   url = i['URLS']\n",
        "#   s = pagesource(url, d)\n",
        "#   med_school = list(s.findAll('small', class_=\"bold\"))\n",
        "#   address = list(s.findAll('div', class_=\"details__address ng-star-inserted\")) \n",
        "#   if len(med_school) == 0:\n",
        "#     mc.append(\"\")\n",
        "#     mcl.append(\"\")\n",
        "#     grad.append(\"\")\n",
        "#   elif len(med_school) == 1:\n",
        "#     a = list(s.findAll('div', class_=\"medical-schools__school ng-star-inserted\"))\n",
        "#     name = a[0].findAll('small', class_='bold')[0].text\n",
        "#     relationship = a[0].findAll('div', class_='')[0].text\n",
        "#     if 'Limited' in relationship:\n",
        "#       mcl.append(name)\n",
        "#       mc.append(\"\")\n",
        "#       grad.append(\"\")\n",
        "#     elif 'Major' in relationship:\n",
        "#       mc.append(name)\n",
        "#       mcl.append(\"\")\n",
        "#       grad.append(\"\")\n",
        "#     elif 'Graduate' in relationship:\n",
        "#       mc.append(\"\")\n",
        "#       mcl.append(\"\")\n",
        "#       grad.append(name)\n",
        "#     else:\n",
        "#       print(\"NEW RELATIONSHIP FOUND : \", name)\n",
        "#       break\n",
        "#   elif len(med_school) > 1:   \n",
        "#       major = []\n",
        "#       limited = []\n",
        "#       graduate = []\n",
        "#       a = list(s.findAll('div', class_=\"medical-schools__school ng-star-inserted\"))\n",
        "#       for i in range(len(a)):\n",
        "#         name = a[i].findAll('small', class_='bold')[0].text\n",
        "#         relationship = a[i].findAll('div', class_='')[0].text\n",
        "#         if 'Limited' in relationship:\n",
        "#           limited.append(name)\n",
        "#         elif 'Graduate' in relationship:\n",
        "#           graduate.append(name)\n",
        "#         elif 'Major' in relationship:\n",
        "#           major.append(name)\n",
        "#         else:\n",
        "#           print(\"New relationship found\")\n",
        "#           break \n",
        "#       if major == []:\n",
        "#         major = ''\n",
        "#       if limited == []:\n",
        "#         limited = ''\n",
        "#       if grad == []:\n",
        "#         grad = ''\n",
        "#       mc.append(major)\n",
        "#       mcl.append(limited)\n",
        "#       grad.append(graduate)\n",
        "#   if len(address) != 0:\n",
        "#     address[0].br.string = ', '\n",
        "#     add.append(address[0].text)\n",
        "#   else:\n",
        "#     add.append(\"\")\n",
        "#   print(index, 'mc', len(mc), mc[index], 'mcl', len(mcl), mcl[index], 'grad', len(grad), grad[index], 'add', len(add), add[index])\n",
        "#   if len(mc) > (index+1):\n",
        "#     break\n",
        "\n"
      ],
      "metadata": {
        "id": "26k1jX71Ux6s",
        "outputId": "db18436e-f093-4eea-9cf8-dd8e05c601a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "26k1jX71Ux6s",
      "execution_count": 28,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 mc 1  mcl 1  grad 1  add 1 \n",
            "1 mc 2  mcl 2  grad 2  add 2 \n",
            "2 mc 3  mcl 3  grad 3  add 3 \n",
            "3 mc 4  mcl 4  grad 4  add 4 \n",
            "4 mc 5  mcl 5  grad 5  add 5 \n",
            "5 mc 6  mcl 6  grad 6  add 6 \n",
            "6 mc 7  mcl 7  grad 7  add 7 \n",
            "7 mc 8  mcl 8  grad 8  add 8 \n",
            "8 mc 9  mcl 9  grad 9  add 9 \n",
            "9 mc 10  mcl 10  grad 10  add 10 \n",
            "10 mc 11  mcl 11  grad 11  add 11 \n",
            "11 mc 12  mcl 12  grad 12  add 12 \n",
            "12 mc 13  mcl 13  grad 13  add 13 \n",
            "13 mc 14  mcl 14  grad 14  add 14 \n",
            "14 mc 15  mcl 15  grad 15  add 15 \n",
            "15 mc 16  mcl 16  grad 16  add 16 \n",
            "16 mc 17  mcl 17  grad 17  add 17 \n",
            "17 mc 18  mcl 18  grad 18  add 18 \n",
            "18 mc 19  mcl 19  grad 19  add 19 \n",
            "19 mc 20  mcl 20  grad 20  add 20 \n",
            "20 mc 21  mcl 21  grad 21  add 21 \n",
            "21 mc 22  mcl 22  grad 22  add 22 \n",
            "22 mc 23  mcl 23  grad 23  add 23 \n",
            "23 mc 24  mcl 24  grad 24  add 24 \n",
            "24 mc 25  mcl 25  grad 25  add 25 \n",
            "25 mc 26  mcl 26  grad 26  add 26 \n",
            "26 mc 27  mcl 27  grad 27  add 27 \n",
            "27 mc 28  mcl 28  grad 28  add 28 \n",
            "28 mc 29  mcl 29  grad 29  add 29 \n",
            "29 mc 30  mcl 30  grad 30  add 30 \n",
            "30 mc 31  mcl 31  grad 31  add 31 \n",
            "31 mc 32  mcl 32  grad 32  add 32 \n",
            "32 mc 33  mcl 33  grad 33  add 33 \n",
            "33 mc 34  mcl 34  grad 34  add 34 \n",
            "34 mc 35  mcl 35  grad 35  add 35 \n",
            "35 mc 36  mcl 36  grad 36  add 36 \n",
            "36 mc 37  mcl 37  grad 37  add 37 \n",
            "37 mc 38  mcl 38  grad 38  add 38 \n",
            "38 mc 39  mcl 39  grad 39  add 39 \n",
            "39 mc 40  mcl 40  grad 40  add 40 \n",
            "40 mc 41  mcl 41  grad 41  add 41 \n",
            "41 mc 42  mcl 42  grad 42  add 42 \n",
            "42 mc 43  mcl 43  grad 43  add 43 \n",
            "43 mc 44  mcl 44  grad 44  add 44 \n",
            "44 mc 45  mcl 45  grad 45  add 45 \n",
            "45 mc 46  mcl 46  grad 46  add 46 \n",
            "46 mc 47  mcl 47  grad 47  add 47 \n",
            "47 mc 48  mcl 48  grad 48  add 48 \n",
            "48 mc 49  mcl 49  grad 49  add 49 \n",
            "49 mc 50  mcl 50  grad 50  add 50 \n",
            "50 mc 51  mcl 51  grad 51  add 51 \n",
            "51 mc 52  mcl 52  grad 52  add 52 \n",
            "52 mc 53  mcl 53  grad 53  add 53 \n",
            "53 mc 54  mcl 54  grad 54  add 54 \n",
            "54 mc 55  mcl 55  grad 55  add 55 \n",
            "55 mc 56  mcl 56  grad 56  add 56 \n",
            "56 mc 57  mcl 57  grad 57  add 57 \n",
            "57 mc 58  mcl 58  grad 58  add 58 \n",
            "58 mc 59  mcl 59  grad 59  add 59 \n",
            "59 mc 60  mcl 60  grad 60  add 60 \n",
            "60 mc 61  mcl 61  grad 61  add 61 \n",
            "61 mc 62  mcl 62  grad 62  add 62 \n",
            "62 mc 63  mcl 63  grad 63  add 63 \n",
            "63 mc 64  mcl 64  grad 64  add 64 \n",
            "64 mc 65  mcl 65  grad 65  add 65 \n",
            "65 mc 66  mcl 66  grad 66  add 66 \n",
            "66 mc 67  mcl 67  grad 67  add 67 \n",
            "67 mc 68  mcl 68  grad 68  add 68 \n",
            "68 mc 69  mcl 69  grad 69  add 69 \n",
            "69 mc 70  mcl 70  grad 70  add 70 \n",
            "70 mc 71  mcl 71  grad 71  add 71 \n",
            "71 mc 72  mcl 72  grad 72  add 72 \n",
            "72 mc 73  mcl 73  grad 73  add 73 \n",
            "73 mc 74  mcl 74  grad 74  add 74 \n",
            "74 mc 75  mcl 75  grad 75  add 75 \n",
            "75 mc 76  mcl 76  grad 76  add 76 \n",
            "76 mc 77  mcl 77  grad 77  add 77 \n",
            "77 mc 78  mcl 78  grad 78  add 78 \n",
            "78 mc 79  mcl 79  grad 79  add 79 \n",
            "79 mc 80  mcl 80  grad 80  add 80 \n",
            "80 mc 81  mcl 81  grad 81  add 81 \n",
            "81 mc 82  mcl 82  grad 82  add 82 \n",
            "82 mc 83  mcl 83  grad 83  add 83 \n",
            "83 mc 84  mcl 84  grad 84  add 84 \n",
            "84 mc 85  mcl 85  grad 85  add 85 \n",
            "85 mc 86  mcl 86  grad 86  add 86 \n",
            "86 mc 87  mcl 87  grad 87  add 87 \n",
            "87 mc 88  mcl 88  grad 88  add 88 \n",
            "88 mc 89  mcl 89  grad 89  add 89 \n",
            "89 mc 90  mcl 90  grad 90  add 90 \n",
            "90 mc 91  mcl 91  grad 91  add 91 \n",
            "91 mc 92  mcl 92  grad 92  add 92 \n",
            "92 mc 93  mcl 93  grad 93  add 93 \n",
            "93 mc 94  mcl 94  grad 94  add 94 \n",
            "94 mc 95  mcl 95  grad 95  add 95 \n",
            "95 mc 96  mcl 96  grad 96  add 96 \n",
            "96 mc 97  mcl 97  grad 97  add 97 \n",
            "97 mc 98  mcl 98  grad 98  add 98 \n",
            "98 mc 99  mcl 99  grad 99  add 99 \n",
            "99 mc 100  mcl 100  grad 100  add 100 \n",
            "100 mc 101  mcl 101  grad 101  add 101 \n",
            "101 mc 102  mcl 102  grad 102  add 102 \n",
            "102 mc 103  mcl 103  grad 103  add 103 \n",
            "103 mc 104  mcl 104  grad 104  add 104 \n",
            "104 mc 105  mcl 105  grad 105  add 105 \n",
            "105 mc 106  mcl 106  grad 106  add 106 \n",
            "106 mc 107  mcl 107  grad 107  add 107 \n",
            "107 mc 108  mcl 108  grad 108  add 108 \n",
            "108 mc 109  mcl 109  grad 109  add 109 \n",
            "109 mc 110  mcl 110  grad 110  add 110 \n",
            "110 mc 111  mcl 111  grad 111  add 111 \n",
            "111 mc 112  mcl 112  grad 112  add 112 \n",
            "112 mc 113  mcl 113  grad 113  add 113 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(len(mc),len(mcl),len(grad),len(add))\n",
        "# hospitals['Affiliation_Major'] = mc\n",
        "# hospitals['Affiliation_Limited'] = mcl\n",
        "# hospitals['Affiliation_Graduate'] = grad\n",
        "# hospitals['Medical_Center_Address'] = add"
      ],
      "metadata": {
        "id": "OR0A_4KaVKje",
        "outputId": "120f3cf9-0a1e-4ef3-b039-10d36fa8a1ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "OR0A_4KaVKje",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9 9 9 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# hospitals.to_csv('Alaska_crosswalk.csv')"
      ],
      "metadata": {
        "id": "56FcOVrwwWLi"
      },
      "id": "56FcOVrwwWLi",
      "execution_count": 25,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}